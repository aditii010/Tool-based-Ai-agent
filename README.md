AI Research Agent (LangChain + Groq)

This project demonstrates how to build a modern AI agent using LangChain that can reason, use tools, and return structured outputs instead of unstructured text.
Unlike basic chatbots, this agent:
Decides when to use tools
Produces validated, structured responses
Avoids hallucinations using schema enforcement

âœ¨ Features

Tool-aware reasoning (web search support)
Structured outputs using Pydantic
Modern LangChain architecture (LCEL)
Clean, extensible design
Production-friendly setup

ðŸ§± Tech Stack

Python 3.10+
LangChain (v1.x)
Groq (LLM backend)
Pydantic
DuckDuckGo Search Tool

ðŸ“ Project Structure
AI_agent01/
â”‚
â”œâ”€â”€ main.py        # Main agent logic
â”œâ”€â”€ tools.py       # Tool definitions
â”œâ”€â”€ .env           # API keys (not committed)
â””â”€â”€ README.md

âš™ï¸ Setup Instructions
Install dependencies
pip install langchain langchain-groq langchain-community python-dotenv

Create .env file
GROQ_API_KEY=your_api_key_here

How It Works
1. Define a schema for output
class ResearchResponse(BaseModel):
    topic: str
    response: str
    sources: list[str]
    tools_used: list[str]


This guarantees clean, predictable outputs.

2. Define tools
@tool
def search(query: str) -> str:
    ...


The model can now decide when to search the web.

3. Build the agent pipeline
prompt â†’ model â†’ tools â†’ structured output


This replaces older agent APIs and ensures reliability.

Run the Agent
python main.py


Example output:

{
  "topic": "Miss World 2005",
  "response": "Unnur Birna VilhjÃ¡lmsdÃ³ttir won Miss World 2005.",
  "sources": ["Wikipedia"],
  "tools_used": ["search"]
}

Key Takeaways

Agents are more than prompts â€” they are structured systems

Tools + schemas = reliable AI

LangChainâ€™s new architecture is composable and clean
